{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T19:17:39.973961Z",
     "start_time": "2024-05-11T19:17:39.971269Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from more_itertools import chunked\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.config.project_paths import get_data_file_path, get_model_save_dir, get_project_root_path\n",
    "from speechbrain.inference.speaker import EncoderClassifier\n",
    "from src.embedding.create_embedding import batch_create_speechbrain_embedding\n",
    "from src.embedding.embedded_audio import EmbeddedAudio\n",
    "from tqdm.auto import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86fd57c5b8d14c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 1341\n"
     ]
    }
   ],
   "source": [
    "# device used for embedding creation\n",
    "DEVICE: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# pretrained model to download and use for embedded creation. must be a speechbrain model compatible\n",
    "# with EncoderClassifier class\n",
    "MODEL_NAME: str = \"speechbrain/spkrec-ecapa-voxceleb\"\n",
    "# Path to a json file, which contains relative paths to audio files\n",
    "ANNOTATION_PATH: Path = \"../data/generated/annotations_reduced_noise.json\"\n",
    "# How many audio files to pass through the model at the same time. Must be >= 1\n",
    "BATCH_SIZE: int = 1\n",
    "# once all the embeddings are calculated, they are pickled to this path.\n",
    "EMBEDDING_PICKLE_PATH: Path = f\"../data/reduced_noise_audio_embeddings.pkl\"\n",
    "\n",
    "model = EncoderClassifier.from_hparams(source=MODEL_NAME, savedir=get_model_save_dir(MODEL_NAME),\n",
    "                                       run_opts={\"device\": str(DEVICE)})\n",
    "\n",
    "annotation_df = pd.read_json(ANNOTATION_PATH, orient=\"records\")\n",
    "rel_audio_paths: List[str] = annotation_df[\"reduced_noise_wav_path\"].to_list()\n",
    "rel_audio_path_batches = chunked(rel_audio_paths, BATCH_SIZE)\n",
    "\n",
    "number_of_batches = len(rel_audio_paths) // BATCH_SIZE + (1 if len(rel_audio_paths) % BATCH_SIZE > 0 else 0)\n",
    "print(f\"Number of batches: {number_of_batches}\")\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "annotations: List[Dict[str, any]] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "864dcf4825604940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a797d01ce9e48438b9dbbf3308ae1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating embeddings:   0%|          | 0/1341 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1341"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "embeddings = []\n",
    "for rel_audio in tqdm([\"..\" + str(real_audio_path[0]) for real_audio_path in rel_audio_path_batches], f\"Creating embeddings\", total=number_of_batches):\n",
    "    if os.path.exists(rel_audio):\n",
    "        audio_embeddings = batch_create_speechbrain_embedding(model, [Path(rel_audio)])\n",
    "        embedded_audio_list = [EmbeddedAudio(audio_rel_path=rel_audio, embedding=audio_embeddings)]\n",
    "        embeddings.extend(embedded_audio_list)\n",
    "    else:\n",
    "        print(f\"File does not exist: {rel_audio}\")\n",
    "\n",
    "\n",
    "\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d134c34fc55f4dde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T20:34:03.927322Z",
     "start_time": "2024-05-11T20:33:55.790179Z"
    }
   },
   "outputs": [],
   "source": [
    "EMBEDDING_PICKLE_PATH: Path = f\"../data/reduced_noise_audio_embeddings.pkl\"\n",
    "with open(EMBEDDING_PICKLE_PATH, \"wb+\") as output_file:\n",
    "    pickle.dump(embeddings, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77c8e403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1341"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "annotations = []\n",
    "for id_path in Path(\"../data/generated/amplitude_audio_files/\").iterdir():\n",
    "    sample_paths = list(id_path.iterdir())\n",
    "    for audio_path in sample_paths:\n",
    "        for audio in audio_path.iterdir():\n",
    "            if str(audio).endswith(\"reduced_noise.wav\"):\n",
    "                annotations.append(\n",
    "                {\n",
    "                    \"reduced_noise_wav_path\": f\"/data/generated/amplitude_audio_files/{id_path.name}/{audio_path.name}/{audio.stem}.wav\",\n",
    "                    \"original_wav_path\": f\"/data/vox2_test/wav/{id_path.name}/{audio_path.name}/{audio.stem}.wav\",\n",
    "                    \"user_id\": id_path.stem\n",
    "                }\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "len(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "417ab4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(annotations).to_json(\"../data/annotations_reduced_noise.json\", orient=\"records\", default_handler=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760971eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
